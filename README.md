<<<<<<< HEAD
# AI Interviewer üé§

A full-stack AI-powered interview platform built with the MERN stack, featuring voice synthesis, real-time AI conversations, and comprehensive recruiter analytics.

## ‚ú® Features

### For Candidates
- üìÑ **Resume Upload** - AI analyzes your resume for context
- üéôÔ∏è **Voice Conversations** - Natural AI-powered interviews
- üìä **Instant Feedback** - Detailed performance report after each interview
- ‚è±Ô∏è **Flexible Duration** - Timer-based interviews (1-120 minutes)

### For Recruiters
- üîê **Secure Authentication** - Powered by Clerk (Google, Email)
- üìù **Job Management** - Create, edit, delete job postings
- üîó **Magic Links** - Unique interview links for each position
- üìà **Analytics Dashboard** - Track candidate performance
- üì• **Report Downloads** - Export candidate reports
=======
üéôÔ∏è TalenTrack:
AI-Powered Interview & Screening SystemNote: This project is currently in the Beta phase. We are actively refining the voice latency and resume parsing logic.

üéØ Problem Statement
In high-volume recruitment, Human Resources teams are often overwhelmed. Screening thousands of resumes manually leads to fatigue, unconscious bias, and slow hiring cycles. Furthermore, scheduling initial screening rounds is a logistical nightmare, and static text-based forms fail to capture a candidate's communication skills or personality.
>>>>>>> feature/auth-system

The Gap: There is no centralized system that automates the entire initial screening process‚Äîfrom parsing a resume to conducting a conversational, voice-based technical interview‚Äîwithout human intervention.

<<<<<<< HEAD
| Layer | Technology |
|-------|------------|
| Frontend | React + Vite + TailwindCSS |
| Backend | Node.js + Express |
| Database | MongoDB + Mongoose |
| Auth | [Clerk](https://clerk.com) |
| AI | Groq API (LLaMA) |
| Voice | Python edge-tts |
=======
üí° Solution Overview
TalenTrack is an automated hiring pipeline. It accepts a candidate's resume, analyzes it to generate a relevant question bank, and conducts a real-time, voice-based interview using a generative AI avatar.
>>>>>>> feature/auth-system

Key capabilities:
Resume Parsing: Extracts skills and experience to tailor the interview.
Contextual Questioning: The AI adapts follow-up questions based on candidate answers, not just a static list.Voice Interaction: Uses low-latency Text-to-Speech (TTS) and Speech-to-Text (STT) for a natural conversational flow.
Automated Scoring: Provides HR with a breakdown of technical accuracy and soft skills.

<<<<<<< HEAD
```
ai-interviewer/
‚îú‚îÄ‚îÄ server.js                 # Express server
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ Job.js               # Job postings (with recruiterId)
‚îÇ   ‚îî‚îÄ‚îÄ Interview.js         # Interview results (with jobId)
‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îú‚îÄ‚îÄ aiController.js      # AI/Groq integration
‚îÇ   ‚îî‚îÄ‚îÄ jobController.js     # Job CRUD operations
‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îú‚îÄ‚îÄ jobs.js              # Job API routes
‚îÇ   ‚îú‚îÄ‚îÄ interview.js         # Interview API routes
‚îÇ   ‚îî‚îÄ‚îÄ resume.js            # Resume parsing routes
‚îú‚îÄ‚îÄ client/                   # React frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LandingPage.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dashboard.jsx      # Recruiter dashboard
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ CandidateFlow.jsx  # Interview flow
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ RecruiterJobPage.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SignInPage.jsx     # Clerk auth
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SignUpPage.jsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ components/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ InterviewRoom.jsx
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ ReportCard.jsx
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ResumeUpload.jsx
‚îÇ   ‚îî‚îÄ‚îÄ .env                  # Frontend env (VITE_CLERK_PUBLISHABLE_KEY)
‚îú‚îÄ‚îÄ python-scripts/
‚îÇ   ‚îî‚îÄ‚îÄ tts.py               # Voice synthesis
‚îî‚îÄ‚îÄ .env                      # Backend env
```

## üöÄ Quick Start

### Prerequisites
- Node.js v18+
- MongoDB (local or Atlas)
- Python 3.7+
- Clerk account ([clerk.com](https://clerk.com))
- Groq API key ([console.groq.com](https://console.groq.com))

### 1. Clone & Install

```bash
# Clone repo
git clone https://github.com/Ayush-Pokhariya-07/ai-interviewer.git
cd ai-interviewer

# Install backend dependencies
npm install

# Install frontend dependencies
cd client && npm install
```

### 2. Setup Python TTS

```bash
pip install edge-tts
# or: pip3 install edge-tts
```

### 3. Configure Environment

**Backend `.env`:**
```env
MONGODB_URI=mongodb+srv://your_connection_string
PORT=5000
GROQ_API_KEY=gsk_your_key_here
CLERK_SECRET_KEY=sk_test_your_key
PYTHON_EXECUTABLE=python3
```

**Frontend `client/.env`:**
```env
VITE_CLERK_PUBLISHABLE_KEY=pk_test_your_key
```

### 4. Start Development

```bash
# Terminal 1: Backend
npm run dev

# Terminal 2: Frontend
cd client && npm run dev
```

Visit `http://localhost:5173`

## üîê Authentication

Routes are protected based on user type:

| Route | Auth Required | User Type |
|-------|---------------|-----------|
| `/` | ‚ùå | Public |
| `/start` | ‚ùå | Candidates |
| `/interview/:jobId` | ‚ùå | Candidates |
| `/sign-in` | ‚ùå | Public |
| `/sign-up` | ‚ùå | Public |
| `/dashboard` | ‚úÖ | Recruiters |
| `/recruiter` | ‚úÖ | Recruiters |

## üì° API Endpoints

### Jobs
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/jobs/all` | Get recruiter's jobs |
| POST | `/api/jobs/create` | Create new job |
| GET | `/api/jobs/:id` | Get job details |
| PUT | `/api/jobs/:id` | Update job |
| DELETE | `/api/jobs/:id` | Delete job + interviews |
| GET | `/api/jobs/:id/interviews` | Get job's candidates |

### Interviews
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/interview/process` | Process interview audio |
| POST | `/api/interview/analyze` | Analyze & save interview |
| GET | `/api/interview/all` | Get all interviews |

### Resume
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/resume/parse` | Parse uploaded resume |

## üß™ Testing

```bash
# Backend health check
curl http://localhost:5000/api/jobs/check/health

# Frontend
open http://localhost:5173
```

## üì¶ Deployment

### Vercel (Frontend)
```bash
cd client
vercel
```

### Railway/Render (Backend)
Ensure environment variables are set in the dashboard.

## ü§ù Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push: `git push origin feature/amazing-feature`
5. Open a Pull Request

## üìÑ License

MIT License - see [LICENSE](LICENSE) for details.

---

Built with ‚ù§Ô∏è by [Ayush Pokhariya](https://github.com/Ayush-Pokhariya-07)
=======
üß± System Components
The architecture follows a microservices-inspired approach to ensure the heavy AI processing doesn't block the user interface.
Frontend (Client):

> Built with React.js (Vite) + Tailwind CSS.
> Handles real-time audio recording and visualization (Web Audio API).

Backend API (Orchestrator):
Node.js / Express. Acts as the traffic controller.
Manages WebSocket connections for streaming audio.

AI Logic Layer:
Python (FastAPI) wrapper around LLMs (OpenAI GPT-4 / LLaMA).
Generates dynamic interview questions and analyzes responses.

Voice Generation Service:
Integration with ElevenLabs/OpenAI Whisper.
Handles the conversion of text responses into realistic audio streams.

Database:
MongoDB: Stores user profiles, structured resume data, and interview logs.
Redis: Used for caching active session states to reduce latency.

üèóÔ∏è High-Level System Architecture
We utilize an event-driven architecture to handle the asynchronous nature of voice processing.
The Flow:

1. User uploads PDF ‚Üí Backend parses text ‚Üí Stored in MongoDB.
2. Interview Start ‚Üí WebSocket connection established.
3. User speaks ‚Üí Audio chunks sent to Backend ‚Üí Forwarded to STT Service.
4. Text sent to AI Logic Layer ‚Üí Generates response.
5. Response sent to TTS Service ‚Üí Audio stream played back to user.

üîÑ Data Flow Diagrams (DFDs)

Level 0 (Context Diagram)
The user interacts with the Interview System. The system interacts with external entities: OpenAI API (Logic) and ElevenLabs (Voice).

Level 1 (Process Decomposition)

1. Auth Module: Verifies JWT tokens.
2. Upload Handler: Sanity checks PDF files, passes to parser.
3. Interview Engine:
   Input: Audio Stream.
   Process: Transcribe -> Context Lookup -> LLM Query -> Audio Gen.
   Output: Audio Stream + Text Log.
4. Reporting Module: Aggregates scores and serves the dashboard.

üóÑÔ∏è Database Design
We chose MongoDB (NoSQL) because interview contexts and resume structures are highly variable (schema-less nature fits best).
Key Collections:
users: Auth details and role (Candidate/Recruiter).
interviews: Stores the session ID, timestamp, and final score.
messages: Array of objects containing { sender: "AI"|"User", text: "...", timestamp: "..." }.
resumes: Parsed JSON data from the uploaded PDF.

Relationships:
One User has many Resumes.
One Resume triggers one or many Interviews.

üìà Scalability & Future Growth
This section addresses how we plan to move from a prototype to production.

1. Horizontal Scaling: The Node.js backend is stateless. We can spin up multiple instances behind an Nginx Load Balancer to handle thousands of concurrent interviews.
2. Queue Management: Currently, resume parsing is synchronous. In production, we will implement RabbitMQ or BullMQ. When a user uploads a resume, it goes into a queue, decoupling the heavy parsing logic from the immediate API response.
3. WebSocket Optimization: To support 10k+ concurrent voice streams, we plan to migrate from standard Socket.io to a specialized Redis Adapter to broadcast messages across clustered server instances.
4. Database Sharding: As the log data grows, we will shard the MongoDB instance based on interview_id to speed up write operations.

üõ°Ô∏è Failure Handling & Reliability
Reliability is critical during a live interview.We have implemented:
Graceful Degradation: If the Voice Generation service (ElevenLabs) times out, the system automatically falls back to a text-only chat interface so the interview doesn't crash.
Circuit Breakers: Implemented on the Python AI service. If the LLM API starts throwing 500 errors, we stop sending requests for 30 seconds to prevent cascading failures.
Session Recovery: If a user disconnects (internet loss), the interview state is saved in Redis. When they reconnect, the system pulls the context immediately, allowing them to resume exactly where they left off.
Data Validation: Strict Zod schema validation on the backend prevents malformed JSON from the AI service crashing the frontend.

üß™ Current Implementation Status
FeatureStatusNotesUser Auth (JWT)
‚úÖ DoneResume PDF Parsing
‚úÖ DoneUses PDF-ParseVoice-to-Text (STT)
‚úÖ DoneOpenAI WhisperAI Response Logic
‚úÖ DonePrompt engineering refinedText-to-Voice (TTS)
‚ö†Ô∏è PartialLatency optimization needed (<2s)Reporting Dashboard
üìù PlannedVisualization of scores

üîÅ Git Workflow & Team Collaboration
We follow the Gitflow Workflow to ensure code stability.
main: Production-ready code.
develop: Integration branch for all new features.
feature/feature-name: Developers work here.
Pull Requests (PRs): Must pass linting checks and require 1 peer review before merging into develop.

üìÅ Repository StructureBash/root
‚îú‚îÄ‚îÄ /client # React Frontend
‚îÇ ‚îú‚îÄ‚îÄ /src
‚îÇ ‚îî‚îÄ‚îÄ /public
‚îú‚îÄ‚îÄ /server # Node.js API Gateway
‚îÇ ‚îú‚îÄ‚îÄ /controllers
‚îÇ ‚îú‚îÄ‚îÄ /models
‚îÇ ‚îî‚îÄ‚îÄ /routes
‚îú‚îÄ‚îÄ /ai-service # Python/FastAPI Microservice
‚îÇ ‚îú‚îÄ‚îÄ /prompts # System prompts for the Interviewer Persona
‚îÇ ‚îî‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ README.md
‚ñ∂Ô∏è DemoLive Link:
[Insert Vercel/Netlify Link Here]
Video Walkthrough: [Insert YouTube/Loom Link Here]
>>>>>>> feature/auth-system
